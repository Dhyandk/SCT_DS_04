# -- coding: utf-8 --

# Install folium if not available
!pip install folium --quiet

# Import all libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import folium
from folium.plugins import HeatMap

# Setup plot style
sns.set(style="whitegrid")

!pip install basemap --quiet
!pip install basemap-data-hires --quiet

"""### Download and Load Dataset"""

import kagglehub

# ğŸ“¥ Download US Accidents dataset
path = kagglehub.dataset_download("sobhanmoosavi/us-accidents")

print("Dataset downloaded to:", path)

"""### Load and Preview Data"""

import os

# ğŸ” Detect CSV file inside downloaded folder
csv_file = [f for f in os.listdir(path) if f.endswith('.csv')][0]
csv_path = os.path.join(path, csv_file)

# âœ… Load only required columns to save memory
use_cols = ['ID', 'Start_Time', 'End_Time', 'Severity', 'Weather_Condition',
            'Start_Lat', 'Start_Lng', 'Crossing', 'Junction', 'Traffic_Signal']

# ğŸ§  Load only first 500,000 rows if you're low on RAM (optional)
df = pd.read_csv(csv_path, usecols=use_cols, nrows=500000)

# â° Convert time column
df['Start_Time'] = pd.to_datetime(df['Start_Time'])

# ğŸ‘€ Preview the data
df.head()

"""### Feature Engineering: Extracting Time Features"""

# Extract features from Start_Time
df['Year'] = df['Start_Time'].dt.year
df['Hour'] = df['Start_Time'].dt.hour
df['Day'] = df['Start_Time'].dt.day_name()

"""### Feature Engineering: Categorizing Time of Day"""

# ğŸ§  Define function to categorize time into periods
def get_time_of_day(hour):
    if 5 <= hour < 12:
        return 'Morning'
    elif 12 <= hour < 17:
        return 'Afternoon'
    elif 17 <= hour < 21:
        return 'Evening'
    else:
        return 'Night'

# ğŸ•“ Apply it to create a new column
df['Time_of_Day'] = df['Hour'].apply(get_time_of_day)

"""### Visualization: Accidents by Time of Day"""

# ğŸ“Š Countplot
plt.figure(figsize=(8,5))
sns.countplot(data=df, x='Time_of_Day', order=['Morning', 'Afternoon', 'Evening', 'Night'], palette='YlOrRd')
plt.title("ğŸ•’ Accidents by Time of Day")
plt.xlabel("Time of Day")
plt.ylabel("Accident Count")

# Add text output
time_of_day_counts = df['Time_of_Day'].value_counts().reindex(['Morning', 'Afternoon', 'Evening', 'Night'])
print("Accident counts by Time of Day:")
print(time_of_day_counts)

plt.show()

"""### Visualization: Accidents Per Year"""

plt.figure(figsize=(10,5))
sns.countplot(data=df, x='Year', palette='viridis')
plt.title("ğŸ“… Accidents Per Year")
plt.xlabel("Year")
plt.ylabel("Accident Count")

# Add text output
year_counts = df['Year'].value_counts().sort_index()
print("Accident counts per Year:")
print(year_counts)

plt.show()

"""### Visualization: Accidents by Hour of Day"""

plt.figure(figsize=(12,6))
sns.countplot(data=df, x='Hour', palette='coolwarm')
plt.title("ğŸ•’ Accidents by Hour of Day")
plt.xlabel("Hour")
plt.ylabel("Number of Accidents")

# Add text output
hour_counts = df['Hour'].value_counts().sort_index()
print("Accident counts by Hour of Day:")
print(hour_counts)

plt.show()

"""### Visualization: Accidents by Day of Week"""

plt.figure(figsize=(10,6))
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.countplot(data=df, x='Day', order=day_order, palette='flare')
plt.title("ğŸ—“ Accidents by Day of Week")
plt.xlabel("Day")
plt.ylabel("Accident Count")

# Add text output
day_counts = df['Day'].value_counts().reindex(day_order)
print("Accident counts by Day of Week:")
print(day_counts)

plt.show()

"""### Visualization: Top 10 Weather Conditions"""

top_weather = df['Weather_Condition'].value_counts().head(10)

print("Accident counts for top 10 weather conditions:")
print(top_weather)

plt.figure(figsize=(10, 10)) # Adjusted figure size for pie chart
plt.pie(top_weather.values, labels=top_weather.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('Spectral', len(top_weather))) # Changed to pie chart
plt.title("ğŸŒ¦ Top 10 Weather Conditions During Accidents")
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
plt.tight_layout()
plt.show()

"""### Visualization: Road Features Involved in Accidents"""

infra_cols = ['Crossing', 'Junction', 'Traffic_Signal']
infra_counts = df[infra_cols].sum()

print("Accident counts by Road Feature:") # Added text output
print(infra_counts) # Added text output

plt.figure(figsize=(8,5))
sns.barplot(x=infra_counts.index, y=infra_counts.values, palette='Set2')
plt.title("ğŸ— Road Features Involved in Accidents")
plt.xlabel("Road Feature")
plt.ylabel("Accident Count")
plt.show()

"""### Heatmap Data Preparation"""

sample_df = df[['Start_Lat', 'Start_Lng']].dropna().sample(n=10000, random_state=42)

"""### Visualization: Accident Hotspots Heatmap (Basemap)"""

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))

# Central USA view
m = Basemap(projection='lcc',
            resolution='l',
            lat_0=39.5, lon_0=-98.35,
            width=5.5E6, height=3.2E6)

m.shadedrelief()
m.drawcoastlines()
m.drawcountries()
m.drawstates()

# Convert lat/lng to projection coordinates
x, y = m(sample_df['Start_Lng'].values, sample_df['Start_Lat'].values)

# Create heatmap with hexbin
hb = plt.hexbin(x, y, gridsize=100, bins='log', cmap='hot', alpha=0.6)

plt.colorbar(hb, label='Log(Number of Accidents)')
plt.title("Heatmap of Accident Hotspots in the USA", fontsize=15)
plt.show()

"""### Coordinate Transformation"""

# Install basemap if not available
!pip install basemap basemap-data-hires --quiet

from mpl_toolkits.basemap import Basemap
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import kagglehub

# ğŸ“¥ Download US Accidents dataset
# This code was moved here to ensure 'path' is defined
try:
    path = kagglehub.dataset_download("sobhanmoosavi/us-accidents")
    print("Dataset downloaded to:", path)
except Exception as e:
    print(f"Error downloading dataset: {e}")
    raise # Re-raise the exception if download fails


# ğŸ” Detect CSV file inside downloaded folder
try:
    csv_file = [f for f in os.listdir(path) if f.endswith('.csv')][0]
    csv_path = os.path.join(path, csv_file)
except NameError:
    print("Error: 'path' variable is not defined after download.")
    raise # Re-raise the error if path is still not defined


# âœ… Load only required columns to save memory
use_cols = ['ID', 'Start_Time', 'End_Time', 'Severity', 'Weather_Condition',
            'Start_Lat', 'Start_Lng', 'Crossing', 'Junction', 'Traffic_Signal']

# ğŸ§  Load only first 500,000 rows if you're low on RAM (optional)
df = pd.read_csv(csv_path, usecols=use_cols, nrows=500000)

# â° Convert time column
df['Start_Time'] = pd.to_datetime(df['Start_Time'])


# Prepare data for heatmap - sample 10000 points
sample_df = df[['Start_Lat', 'Start_Lng']].dropna().sample(n=10000, random_state=42)


# Initialize the Basemap object
# Central USA view
m = Basemap(projection='lcc',
            resolution='l',
            lat_0=39.5, lon_0=-98.35,
            width=5.5E6, height=3.2E6)


# Convert lat/lng to projection coordinates
x, y = m(sample_df['Start_Lng'].values, sample_df['Start_Lat'].values)
print("Coordinate transformation successful.")

"""### Identify Top Hotspots"""

import numpy as np

# Define bins
gridsize = 100
xmin, xmax = min(x), max(x)
ymin, ymax = min(y), max(y)

xedges = np.linspace(xmin, xmax, gridsize)
yedges = np.linspace(ymin, ymax, gridsize)

# Create 2D histogram
heatmap, xedges, yedges = np.histogram2d(x, y, bins=[xedges, yedges])



import pandas as pd

# Flatten to tabular format
heatmap_df = pd.DataFrame({
    'x_bin': np.repeat(range(heatmap.shape[0]), heatmap.shape[1]),
    'y_bin': list(range(heatmap.shape[1])) * heatmap.shape[0],
    'count': heatmap.flatten()
})

# Filter non-zero cells (hotspots)
hotspots = heatmap_df[heatmap_df['count'] > 0]



top_hotspots = hotspots.sort_values(by='count', ascending=False).head(10)
print(top_hotspots)

"""### Hotspot Analysis"""

print("Total accident cells:", len(hotspots))
print("Average accidents per active cell:", hotspots['count'].mean())
print("Max accidents in one cell:", hotspots['count'].max())
print("Std deviation:", hotspots['count'].std())

"""### Convert Hotspot Coordinates to Lat/Lng"""

# Convert x_bin, y_bin to approximate map coordinates
x_center = (xedges[top_hotspots['x_bin']] + xedges[top_hotspots['x_bin'] + 1]) / 2
y_center = (yedges[top_hotspots['y_bin']] + yedges[top_hotspots['y_bin'] + 1]) / 2

# Convert back to Lat/Lng using Basemap inverse transformation
lon, lat = m(x_center, y_center, inverse=True)

# Add to DataFrame
top_hotspots['Latitude'] = lat
top_hotspots['Longitude'] = lon

"""### Visualization: Accident Hotspots Heatmap (Folium)"""

import folium
from folium.plugins import HeatMap

# ğŸŒ Use 100,000 points â€” adjust up to 500,000 if RAM allows
map_df = df[['Start_Lat', 'Start_Lng']].dropna().sample(500000)

# ğŸ—º Create base map with better tile design
base_map = folium.Map(
    location=[map_df['Start_Lat'].mean(), map_df['Start_Lng'].mean()],
    zoom_start=5,
    tiles='Stamen Toner',  # Darker theme for glowing contrast
    attr='Map tiles by Stamen Design, under CC BY 3.0. Data by OpenStreetMap, under ODbL.' # Added attribution
)

# ğŸ”¥ Add HeatMap layer
HeatMap(
    map_df.values,
    radius=5, # Reduced radius
    blur=10, # Reduced blur
    max_zoom=10,
    gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'orange', 0.8: 'red'}
).add_to(base_map)

# ğŸ’¥ Display final map
# Save map to an HTML file
# ğŸ’¾ Save map to HTML
base_map.save("heatmap.html")
base_map
